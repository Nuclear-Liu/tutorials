= Storm
Hui.Liu <mexn-0808@outlook.com>
:toc: left
:toclevels: 5
:toc-title: 目录

Storm 是 Twitter 开源的**实时**数据处理框架；实现**高频数据**和**大规模数据**的实时处理。

== Storm 核心概念

=== 1. Topology 拓扑

拓扑(*Topology*)是由**计算的节点(node)**与表示**计算结果的边(edge)**组成的图，并由提供**连续数据的数据源**来驱动。
节点(node)st代表一些独立的计算，扮演了最简单的计算模型；
边(edge)代表节点间的数据的传递。

=== 2. Tuple 元组

元组(*Tuple*)是拓扑(Topology)中节点间传输数据的格式，它本身是一个**有序**的数值序列，其中每个数值都会被赋予一个**命名**；
一个元组只是一系列数值的**列表**，Storm 本身提供了一种机制来为列表中的每个数值**赋予命名**。

发送元组到任意节点的过程被称为发射(*emit*)一个元组；

同一个元组(tuple)中**值**的类型是**动态**的，并不需要提前声明；
但 Storm 需要知道如何对元组中的值进行**序列化**，以便让它可以在拓扑(topology)节点间实现元组的传递。
如果是自定义类型，则需要提供对应自定义的序列化方法。

=== 3. Stream 流

流(*Stream*)是一个无边界的元组(tuple)序列。

在拓扑(topology)中，一个流(stream)是拓扑(topology)中两个节点间一个无边界的元组序列；
一个拓扑(topology)可以包含任意数量的流(stream)，除了拓扑的第一个节点(spout)是从数据源读取数据外，每个节点(bolt)可以接收一个或多个流(steam)作为输入。

=== 4. Spout 数据源

数据源(*Spout*)是拓扑(topology)的流(stream)数据源头；通常是外部数据源读取数据向拓扑(topology)中发射(emit)元组(tuple)。

数据源(spout)没有对数据的处理过程，仅仅作为数据流的源头，从数据源读取数据，向数据处理者(*bolt*)类型的节点发射(emit)元组。

=== 5. Bolt 数据处理者

数据处理者(Bolt)负责完成从输入流(stream)接收元组(tuple)，对元组(tuple)进行计算或转换操作，以及可能会发射(emit)新的元组(tuple)形成新的输出流(stream)。

=== 6. Grouping 流分组

流分组定义了元组在数据源(spout)和数据处理者(bolt)以及数据处理者(bolt)和数据处理者(bolt)实例之间如何进行传递。

==== shuffleGrouping 随机分组

随机分组(shuffledGrouping)采用随机策略（不是轮询策略）确保每个 bolt 实例能够尽可能接收数量相等的元组，以便在 bolt 实例之间实现负载均衡。

随机分组在**对数据分发没有特殊需求**的场景下是非常有用。

==== fieldsGrouping 字段分组

字段分组(fieldGrouping)更具指定的字段值，保证将含有相同字段值的元组(tuple)发射(emit)到同一个数据处理者(blot)实例。

==== globalGrouping 全局分组

所有的元组(tuple)被路由到一个单独的任务(task)中，并且选择 task 的 Id 最小的；
如果使用此策略，设置并行度来提高并发率将失去意义：
所有的元组(tuple)将会发送到同一个Bolt处理，将成为整个拓扑的性能瓶颈。

==== allGrouping 广播分组

对每个元组(tuple)广播发送给所有的下一个数据处理者(bolt)。

==== noneGrouping 不分组

Storm 不具体实现分组方式。

==== directGrouping 直接分组

元组(tuple)的发射时指定数据处理者(bolt)的具体 task

==== localOrShuffleGrouping 本地或随机分组

如果目标数据处理者(bolt)有一个或多个 task 与发射元组(tuple)的实例在同一个工作进程中，则优先随机发射(emit)本地数据处理者(bolt)实例。

==== partialKeyGrouping 关键字分组

与字段分组相似，根据指定的字段进行分组；这种方式会考虑下游数据处理者(bolt)数据处理的均衡性问题，在输入数据源关键字不均衡时会有更好的性能。

=== 7. executor 执行器

执行器(executor)就是工作节点 JVM 上的执行数据源(spout)或数据处理者(bolt)的线程。

一个工作节点(worker)可以有一个或多个执行器(executor)。


[WARNING]
====
* 一个工作节点(worker)不会为多个拓扑(topology)服务。
* 一个拓扑(topology)可以使用一个或多个工作节点(worker)运行任务。
====

=== 8. task 任务

任务(task)即在执行线程(执行器)上运行的数据源(spout)或数据处理者(bolt)实例。

[TIP]
====
每个执行器(executor)可以运行一个或多个任务(task)。
====

== 应用 Storm

[TIP]
====
Storm 依赖：
[source,xml]
----
<dependency>
    <groupId>org.apache.storm</groupId>
    <artifactId>storm-core</artifactId>
    <version>1.2.4</version>
    <scope>provided</scope>
</dependency>
----
* 在本地环境中，本地运行项目是可以不设置 ``scope`` 的值；
* 在生产环境中 ``scope``必需要设置为 ``provided`` 。
====

=== 数据源组件 Spout

.Spout class design patterns
[plantuml,format="svg",id="spout"]
----
include::uml/spout.puml[]
----

* ``IComponent``: 通过拓扑( *Topology* )组件的接口 —— 定义了组件的**配置**和**输出规范**
* ``ISport``: 定义了 *Sport* 的职责
* ``IRichSpout``: 完整的 *Sport* 职责描述接口，包含了 ``ISport`` 和 ``IComponent``
* ``BaseRichSpout``: ``IRichSpout`` 的部分实现，是自定义继承实现 *Sport* 的基类

使用 ``BaseRichSpout`` 必须实现的方法：

. ``void open(Map conf, TopologyContext context, SpoutOutputCollector collector)``: 在 Storm 准备运行时调用一次(*初始化*)
. ``void nextTuple()``: 当 Storm 准备取下一个元组(tuple)时，由 Storm 调用
. ``void declareOutputFields(OutputFieldsDeclarer declarer)``: 为 Sport 发射的元组所有字段**命名**

=== 数据处理者 Bolt

.Bolt class design patterns
[plantuml,format="svg",id="bolt"]
----
include::uml/bolt.puml[]
----

* ``IBolt``: 定义了一个数据处理者(bolt)的职责
* ``IComponent``: 拓扑(topology)的通用接口(包括spout和bolt) —— 定义了组件的配置与输出
* ``IRichBolt``: 一个完整的数据处理者(bolt)接口(包含(IBolt)和(IComponent))
* ``IBasicBolt``: 精简版数据处理者接口，相比较于 ``IRichBolt`` 支持部分功能
* ``BaseRichBolt``: 部分实现 ``IRichBolt`` 是自定义继承实现数据处理者(bolt)的基类
* ``BaseBasicBolt``: 部分实现 ``IBasicBolt`` 是自定义继承实现数据处理者(bolt)的基类

使用 ``BaseBasicBolt`` 必须实现的方法：

. ``void execute(Tuple input, BasicOutputCollector collector)``: 当元组(tuple)被发射到当前数据处理者(bolt)时调用
. ``void declareOutputFields(OutputFieldsDeclarer declarer)``: 为当前数据处理者(bolt)发射(emit)出的元组定义**字段名称**

=== 创建拓扑 Topology

[source,text]
----
TopologyBuilder builder = new TopologyBuilder();

builder.setSpout("commit-feeder", new CommitFeeder());

builder.setBolt("email-extractor", new EmailExtractor())
        .shuffleGrouping("commit-feeder");

builder.setBolt("email-counter", new EmailCounter())
        .fieldsGrouping("email-extractor", new Fields("email"));

Config config = new Config();
config.setDebug(true);

StormTopology commitCountTopology = builder.createTopology();
----

=== 心跳元组 Tick Tuple

心跳元组(tick tuple)用于触发定时事件的元组(tuple)。
心跳元组(tick tuple)配置后，可以按照用户定义的频率以及时间点，在 bolt 上**周期地调用** ``execute`` 方法。
在 ``execute`` 中检查元组是否被定义为由系统周期性触发的动作（或是一个普通的元组）并处理心跳元组(tick tuple)。
正常情况下的拓扑的元组(tuple)只负责将数据按默认的流模式，而**心跳元组**(tuple)则是基于系统的**心跳触发**来传输数据。

. 重写 ``getComponentConfiguration`` 方法
+
配置心跳元组
. 在 ``execute`` 中判断是否为心跳元组

[TIP]
====
心跳元组的##**发射频率**##

心跳发射频率**并不精确**，这里采取的是一种最佳能效机制。

发射到 bolt 的心跳元组将和其他元组一起按队列排序，排队等待前面的 bolt 完成 ``execute`` 方法的调用。
如果流中心跳元组前的其他元组的执行存在较高的延迟，心跳元组将继续等待。
====

[IMPORTANT]
====
**##线程安全##**

在使用 Storm 过程中经常需要在内存中使用数据结构(类非静态变量)；
由于 ``execute()`` 同一时间只会执行一个元组的处理，所以在线程级是安全的。

当元组在**组件中进行传递**时，如何实现元组上的值可以在不同线程上执行序列化？
当发射内存中的数据结构时，没有复制就直接使用在另一个线程上执行序列化，而此时这个数据正在发生变化，系统将抛出 ``CurrentModificationException`` 异常。

* 保证数据不可变更
* 基于 bolt 的方法 ``execute()`` 创建自有线程，自己保证线程安全问题。
====

=== 网络化扩展

[TIP]
====
**网络化扩展**

一个具备网络化扩展的系统，需要具备**不通过停机**就可以基于网络集群化实现**运算能力的扩展**，也称为**需求的网络化扩展**。
====

==== Storm 并行性机制

===== 1. 使用并行性触点

使用并行性触点是在数据源(spout)和数据处理者(blot)层面通过设置数据源(spout)和数据处理者(bolt)实例的并发数量实现。

* 设置数据源(spout)的并行性触点
+
在构建拓扑(topology)时，通过构建器 ``TopologyBuilder`` 的 ``setSpout(String id, IRichSpout spout, Number parallelism_hint)`` 方法的 ``##parallelism_hint##`` 参数配置。

* 设置数据处理者(bolt)的并性触点
+
在构建拓扑时，通过构建器 ``TopologyBuilder`` 的 ``setBolt(String id, IBasicBolt bolt, Number parallelism_hint)`` 方法的 ``##parallelism_hint##`` 参数配置。

===== 2. 调解执行器与任务

默认情况下执行器(executor)仅有一个任务(task)。

修改执行器(executor)内任务(task)数的方式有两种：

* 在构建拓扑(topology)时，构建器 ``TopologyBuilder`` 调用 ``setSpout`` / ``setBolt`` 后调用 ``##setNumTasks(Number val)##`` 方法指定具体任务数；
* 通过 Web UI 调整；


===== 3. 调整工作节点数量

默认情况下拓扑(topology)使用一个工作节点(worker)。

在提交拓扑(topology)到运行环境是通过 ``Config`` 的 ``setNumWorkers(int workers)`` 执行拓扑使用的节点数量。

=== 拓扑(topology)设计方法

[quote, Donald Kunth]
--
在大约 97% 的情况下，你都应该忘掉哪些影响较小的效率问题，过早的优化时万恶之源。
--


设计拓扑一般可以分解为五个步骤：

. 定义问题/构造一个概念上的解决方案
+
首先清晰的理解问题，同时还要记录**任何潜在的需求**（包括**处理速度**）。
+
然后对解决方案进行初步建模(不用于实现的)，来阐述问题的核心诉求。

. 将解决方案映射到 Storm 中
+
分解提出的问题并形成解决方案，评估将解决方案映射到 Storm 技术相关原语(即 Storm 概念)上；实现第一个拓扑(topology)设计。

. 实现初始方案
+
根据初步拓扑(topoly)设计实现相关组件并部署。
+
.. 首先考虑流经系统的**数据特性**：考虑数据流本身施加的要求定义数据源(Spout)，确定**输入数据点**，将数据点表示为元组(tuple)
.. 确定解决问题需要的最终数据点，并表示为元组(tuple)
.. 在输入元组和最终元组之间，补充完整数据处理方法

. 扩展拓扑(topology)
+
利用 Storm 工具，对拓扑(topology)实施扩容。

. 运行中优化
+
观察各组件运行情况以及实际需求的变化，做出相应的调整。

.. 检查每个处理点，通过调整执行器和任务的方式，不断进行尝试性调整，从而建立扩展机制；
.. 当某些组件无法继续扩展时，回顾设计，对某些组件重新设计以便优化整体的扩展性；

[IMPORTANT]
====
重要信息
====
