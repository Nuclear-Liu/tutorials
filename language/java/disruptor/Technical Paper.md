# LMAX Disruptor：用于在并发线程之间交换数据的有界队列的高性能替代方案 (High performance alternative to bounded queues for exchanging data between concurrent threads)

> Martin Thompson · Dave Farley · Michael Barker · Patricia Gee · Andrew Stewart - Version 4.0.0.RC2-SNAPSHOT, May 2011

## 摘要 Abstract

LMAX 的成立是为了创造一个非常高性能的金融交易所。
作为实现这一目标的工作的一部分，我们评估了设计此类系统的几种方法，但是当我们开始测量这些方法时，我们遇到了传统方法的一些基本限制。

许多应用进程依赖队列在处理阶段之间交换数据。
我们的性能测试表明，以这种方式使用队列时，延迟成本对磁盘（基于 RAID 或 SSD 的磁盘系统）的 IO 操作成本处于同一数量级 —— 非常慢。
如果端到端操作中有多个队列，这将增加数百微妙的整体延迟。
显然还有优化的空间。

进一步调查对计算机科学的关注使我们意识到传统方法（例如队列和处理节点）中固有的关注点的混论导致多线程实现中的争用，这表明可能有更好的方法。

考虑现在 CPU 的工作方式，我们喜欢称之为”机械同情“("mechanical sympathy")，使用良好的设计实践，重点关注梳理问题，我们提出了一种数据结构和一种我们称之为 Disruptor 的使用模式。

测试表明，将 Disruptor 用于三级管道的平均延迟比等效的基于队列的方法低 3 个数量级。
此外，对于相同的配置， Disruptor 处理的吞吐量大约高出 8 倍。

这些性能改进代表了围绕并发编程的思想发生了重大变化。
这种新模式是任何需要高吞吐量和低延迟的异步事件处理框架的理想基础。

在 LMAX ，我们创建了一个订单匹配引擎、实施风险管理和一个高可用的内存交易处理系统，所有这些都是在这个模式上取得了巨大的成功。
这些系统中的每一个都设定了新的性能指标，据我们所知，这些标准是无与伦比的。

然而，这不仅与金融行业相关的专业解决方案。
Disruptor 是一种通用机制，它以最大化性能的方式解决并发编程中的复杂问题，并且易于实现。
尽管一些概念可能看起来不寻常，但根据我们的经验，构建这种模式的系统比类似的机制更容易实现。

与同类方法相比， Disruptor 具有更少的写入争用、更低的并发开销并且对缓存更友好，所有这些都导致更高的吞吐量以及更低的延迟和更少的抖动。
在中等时钟速率的处理器上，我们已经看到每秒超过 2500 万消息和低于 50 纳秒的延迟。
与我们见过的任何其他实现相比，这种性能是一个显著的改进。
这非常接近处理器在内核之间交换数据的理论极限。

## 1. 概述 Overview

Disruptor 是我们努力在 LMAX 创建世界上最高性能的金融交易所的结果。
早期的设计侧重于 `SEDA` 和 `Actor` 派生的架构，使用管道来提高吞吐量。
在分析各种实现之后，很明显，管道中各个阶段之间的事件队列主导了成本。
我们发现队列还引入了延迟和高抖动。
我们花费了大量精力来开发具有更好性能的新队列实现。
然而，很明显，由于生产者、消费者及其数据存储设计问题混为一谈，队列作为一种基本数据结构是有限的。
Disruptor 是我们努力创建一个并发结构的结果，该结构可以干净地分离这些问题。

## 2. 并发的复杂性 The Complexities of Concurrency

在本文档和一般计算机科学的上下文中，并发不仅意味着两个或多个任务并行发生，而且还意味他们争夺资源访问权。
争用的资源可能是数据库、文档、套接字甚至是内存中的某个位置。

代码的并发执行与两件事有关，**互斥**和**变化的可见性**。
**互斥**是关于管理对某些资源的竞争更新。
**更改的可见性**是关于控制何时使这些更改对其他线程可见。
如果您可以消除竞争更新的需要，则可以避免互斥的需要。
如果你的算法可以保证任何给定资源只被一个线程修改，那么互斥就没有必要了。
读写操作要求所有更改对其他线程可见。
然而，只有争用的写操作需要更改的互斥。

在任何并发环境中，成本最高的操作是竞争写访问。
让多个线程写入同一资源需要复杂且昂贵的协调。
通常这是通过采用某种锁定策略来实现的。

## 2.1. 锁的成本 The Cost of Locks

**锁**提供互斥并确保更改的可见性以及有序的方式发生。
锁是非常昂贵的，因为它们在争用时需要仲裁。
这种仲裁是通过上下文切换到操作系统内核来实现的，操作系统内核将挂起等待锁的线程，直到它被释放。
在这样的上下文切换期间，以及将控制权释放给操作系统，操作系统可能决定在它拥有控制权的同时执行其他内务处理任务。执行上下文可能会丢失先前缓存的数据和指令。
这对现代处理器产生严重的性能影响。
可以使用**快速用户模式锁**，但这些只有在不争用时才有真正的好处。

我们将通过一个简单的演示来说明锁的成本。
本实验的重点是调用了一个函数，该函数在循环中将 64 位计数器递增 5 亿次。
如果用 Java 编写，这可以由 2.4Ghz Intel Westmere EP 上的单个线程执行，只需 300 毫秒。
语言对于这个实验并不重要，所有具有相同基本原语的结果都是相似的。

一旦引入锁来提供互斥，即使锁尚未竞争，成本也会显著上升。
当两个或更多线程开始竞争时，成本会再次增加，数量级会增加。
这个简单实验的结果如下表所示：

_Table 1. 争用的比较成本 Comparative costs of contention_

| Method                            | Time(ms) |
|-----------------------------------|---------:|
| Single thread                     |      300 |
| Single thread with lock           |   10,000 |
| Two threads with lock             |  224,000 |
| Single thread with CAS            |    5,700 |
| Two threads with CAS              |   30,000 |
| Single thread with volatile write |    4,700 |

## 2.2. "CAS" 的成本 The Costs of "CAS"

当更新的目标时单个字时，可以采用一种比使用锁更有效的替代方法来更新内存。
这些替代方案基于在现代处理器中实现的原子或互锁指令。
这些通常称为 CAS（比较和交换）操作，例如 x86 上的 `lock cmpxchg` 。
CAS 操作是一种特殊的机器代码指令，它允许将内存中的一个字有条件地设置为原子操作。
对于**"增加计数器实验"**，每个线程都可以在循环中旋转读取计数器，然后尝试以原子方式将其设置为新的增量值。
旧值和新值作为参数提供给该指令。
如果在执行操作时，计数器的值与提供的预期值匹配，则用新值更新计数器。
另一方面，如果该值不符合预期，则 CAS 操作将失败。
然后由尝试执行更改的线程重试，重新读取从该值递增的计数器，以此类推，直到更改成功。
这种 CAS 方法比锁更有效，因此它不需要上下文切换到内核进行仲裁。
然而， CAS 操作不是免费的。
处理器必须锁定其指令管道以确保原子性，并使用内存屏障使更改对其它线程可见。
通过使用 `java.util.concurrent.Atomic*` 类， CAS 操作在 Java 中可用。

如果进程的关键部分比简单的计数器增量更复杂，则可能需要使用多个 CAS 操作的复杂状态机来协调争用。
使用锁开发并发进程是困难的；使用 CAS 操作和内存屏障开发无锁算法要复杂很多倍，而且很难证明它们是正确的。

理想的算法是只有一个线程拥有对单个资源的所有写入，而其他线程读取结果。
要在多处理器环境中读取结果，需要内存屏障以使更改对在其他处理器上运行的线程可见。

## 2.3. 内存屏障 Memory Barriers

## 2.4. 缓存行 Cache Lines

## 2.5. 队列的问题 The Problems of Queues

## 2.6. 管道与图 Pipelines and Graphs
