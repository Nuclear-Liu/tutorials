# Kafka

Kafka 是 Apache 开源的**分布式事件流处理平台**；
Kafka Streaming 插件提供了运行在应用端的实时流计算处理能力；

消息队列优势：
* 系统间解耦
* 异步通信
* 削峰填谷

> AKF
> 
> * `x` 轴：**单点问题高可用**
> 
>     数据**副本**，避免节点数据不可用（基于网络）；
>     数据主备情况下数据同步问题（一主多备（一致性），读写分离（吞吐量））；**Kafka 只允许再主上进行对外提供服务（读写数据），从节点只做数据备份；**
> 
>     一致性方面， Kafka 通过副本保证一致性；
> 
> * `y` 轴：**业务划分**，Kafka 中即 `Topic` 
> 
>     会存在性能瓶颈，需要 `z` 分片、分治
> 
> * `z` 轴：**分片、分治**，Kafka 中即 `partition`
> 
>     如何保证生产-消费**顺序**的一致性；（大数据中：分为必然的分治，数据之间无关和聚合，数据之间有关联）
> 
>     * 无关数据生产的时候放到不同的分区，达到后续无关的并行度；
>     * 有关联数据生产的时候放到相同的分区，避免使用分布式锁；
> 
>     > 分区内部有序，分区外无须；通过偏移量 `offset`

## Kafka 架构

> Topic 是一个逻辑概念；
> Partition 是物理的；

* Zookeeper 集群： 处理分布式协调；

    选择 `Controller` 过程；
    存储元数据；

* Broker 进程：每个 Broker 负责具体存储每个逻辑 Topic 的 Partition 分片；

    * `Controller` 控制者（主）制造元数据信息（ `metadata` ，集群内信息）；
    * 

* `admin-api` 连接 Zookeeper 获取具体 `Controller`

* `Producer`

    向 `Partition` 分区填充数据；

    新版本中不再从 Zookeeper 获取 Broker 注册信息；
    新版本中需要手工给出 Broker 列表，可以从 Broker 列表中的任意一个**节点**获取到所有的节点信息（减轻 Zookeeper 负担）；

* `Consumer`

    新版本中不再从 Zookeeper 获取 Broker 注册信息；
    新版本中需要手工给出 Broker 列表，可以从 Broker 列表中的任意一个**节点**获取到所有的节点信息（减轻 Zookeeper 负担）；

    多个 Consumer 下： 
    Partition 分区与 Consumer 之间可以是一对一或多对一的关系；
    一对多情况容易破坏有序性，应尽量避免；

    多个 Consumer 消费的情况下需要再 `offset` 上加锁或排序保证消息消费的有序性；

    通过**分组(Group)**使的不同的应用场景下的的消费相互隔离， Kafka 保证不同组的 Consumer 可以隔离消费数据；

    > 数据的重复利用建立在 Group 上；
    > Group 内保证消费的顺序性一致性；
  
    Consumer 消费时可能出现节点不可用；

    * 消息丢失
    * 消息重复消费

    > Consumer 运行时，在自己内部（**内存中**）维护 `offset` 消费进度；
    > 
    > 老版本中 Consumer 将 `offset` 默认维护到 Zookeeper 中；
    > 
    > 新版本中 Kafka 在 Broker 中自动维护了一个关于 `offset` 的一个 Topic （ `__consumer_offsets` 默认 50 个 Partition 分区）， Consumer 将 `offset` 默认维护到 Kafka 的 `offset` 的 Topic 中；
    > 
    > 支持存储第三方(`redis` `MySQL`)；
    >
    > offset 维护的：节奏、频率、维护的先后顺序？
    > 根据业务不同处理方式不同：定时（5s)更新（丢失 offset 造成重复消费）、同步更新业务和 offset （放到同一个事务中，避免重复消费，与丢失数据（没有控制好更新 offset 顺序，会造成 Offset 重复））、


> 数据亲源性、亲和性
> 
> 保证相关数据产生和处理过程尽量放到相同处理流中；
> 并发下 Kafka 客户端注意一致性问题，生产的时候相关的放到一个分区；

### Kafka 与磁盘和网卡的技术点



## Kafka 三个关键功能：

* **发布**（写入）和**订阅**（读取）事件流，包括从其他系统连续导入/导出数据；
* 可靠地**持久化存储**事件流，只要您愿意；
* 在事件发生时或事后**处理**事件流（异步能力）；

## 消息队列工作模式：

1. 至多一次：

   消息生产者将数据写入消息系统，由消费者负责读取消息，一旦消息被确认消费，消息服务器会主动删除消费的消息；
   这种方式只允许一个消费者消费，消息队列中的数据不允许被重复消费（ActiveMq)；

2. 没有限制：

   消息生产者将数据写入消息系统，该消息可以被多个消费者同时消费，并且同一个消费者可以多次消费消息服务器中的同一个记录，每个消费者的消费（记录消费偏移量）相互独立（主要因为消息服务器可以长时间存储海量消息）（Kafka）；


